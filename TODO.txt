TO-DO LIST IMPLEMENTASI
CRAWLING PENELITIAN
- MASUKKAN FILE FRONTIER v
- SEMUA ISI FILE DI CRAWL
- COMMAND "scrapy crawl research -a url='<url>' -a allow='<allow>'" v
- SAVE FILE KE "result.csv" v

CRAWLING AKADEMIK
- MASUKKAN FILE FRONTIER
- MASUKKAN REGEX YANG MATCH UNTUK DIAMBIL
- SEMUA ISI FILE DI CRAWL
- COMMAND "scrapy crawl academic -a url='<url>' -a allow='<allow>'" v
- SAVE FILE KE "result.csv" v

EXTRACTOR PENELITIAN
- MASUKKAN HASIL RESULT CRAWL "result.csv" v 
- SEMUA LINK DALAM FILE DI EKSTRAKSI
- COMMAND "python table_extractor.py <url>" v -baru sampai cleaning
- EKSTRAKSI ISI TABEL
- UBAH KE BENTUK BIBLIOGRAFI
- COMMAND "python list_extractor.py <url>" v
- MENGHASILKAN FILE-FILE HASIL EKSTRAKSI SEBUAH URL v
- SEMUA FILE DI EKSTRAKSI MENGGUNAKAN ANYSTYLE-PARSER
- SEBUAH FILE DI EKSTRAKSI DENGAN ANYSTYLE-PARSER v
- COMMAND "python run.py <folder>" v
- HASIL EKSTRAKSI DI SIMPAN KE DALAM MONGODB

EXTRACTOR AKADEMIK
- MASUKKAN HASIL RESULT CRAWL "result.csv" v 
- SEMUA LINK DALAM FILE DI EKSTRAKSI
- COMMAND "python template_extractor.py <url> <template>" v 
- HASIL EKSTRAKSI DI SIMPAN KE DALAM MONGODB v

INTERAKSI DALAM WEB
- FRONTEND TIAP COMMAND v 
- FRONTEND HASIL TIAP COMMAND
- FRONTEND HASIL EKSTRAKSI 